# Nimbal airflow workflows## Set Up Airflow 2.0All set up steps are based on the documentation (https://airflow.apache.org/docs/apache-airflow/stable/start/local.html)1. Install system dependencies```sudo apt-get install -y --no-install-recommends \        freetds-bin \        krb5-user \        ldap-utils \        libffi6 \        libsasl2-2 \        libsasl2-modules \        libssl1.1 \        locales  \        lsb-release \        sasl2-bin \        sqlite3 \        unixodbc```2. Install airflow through pip with the constraints fileThe constraints file ensures that there is no conflicts in dependencies```AIRFLOW_VERSION=2.0.1PYTHON_VERSION="$(python --version | cut -d " " -f 2 | cut -d "." -f 1-2)"# For example: 3.6CONSTRAINT_URL="https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt"# For example: https://raw.githubusercontent.com/apache/airflow/constraints-2.0.1/constraints-3.6.txtpip install "apache-airflow==${AIRFLOW_VERSION}" --constraint "${CONSTRAINT_URL}"```3. initialize DB and set admin user```# initialize the databaseairflow db initairflow users create \    --username admin \    --password admin \    --firstname Peter \    --lastname Parker \    --role Admin \    --email spiderman@superhero.org```4. Test webserver and scheduler (Note: login is the airflow user created)On two seperate terminals run `airflow webserver --port` and `airflow scheduler`Once the webserver is up, open `localhost:8080` on your webbrowser and test that it works5. Set path to dags.Once everything is working, make sure the `dags_folder` in your `$AIRFLOW_HOME/airflow.cfg` is pointing to the path where your DAGs are stored.## Install PostgresSQL Database (optional)1. Install PostgresSQL (https://www.postgresql.org/)2. Install airflow PostgresSQL packages```pip install "apache-airflow[postgres]"```3. Update connection in `$AIRFLOW_HOME/airflow.cfg````# Enables parallel processing as opposed to SequentialExecutorexecutor = LocalExecuter# points airflow to (e.g. sql_alchemy_conn=postgresql+psycopg2://airflow_user:airflow_user@localhost/airflow_db)sql_alchemy_conn = postgresql+psycopg2://<user>:<password>@<host>/<db>```4. Create Database and User in PostgresSQL by running `sudo -u postgres psql` then the commands below:```CREATE DATABASE airflow_db;CREATE USER airflow_user WITH PASSWORD 'airflow_user';GRANT ALL PRIVILEGES ON DATABASE airflow_db TO airflow_user;```5. initialize db again `airflow db init`        